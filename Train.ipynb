{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Import necessary Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T15:52:20.196125Z","iopub.status.busy":"2023-07-02T15:52:20.194794Z","iopub.status.idle":"2023-07-02T15:52:23.030658Z","shell.execute_reply":"2023-07-02T15:52:23.029444Z","shell.execute_reply.started":"2023-07-02T15:52:20.196079Z"},"trusted":true},"outputs":[],"source":["import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.pipeline import make_pipeline\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, Normalizer\n","from sklearn.decomposition import PCA\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.metrics import *\n","from collections import Counter\n","from sklearn.model_selection import LearningCurveDisplay, learning_curve"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Load and save model"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T15:52:24.487909Z","iopub.status.busy":"2023-07-02T15:52:24.487439Z","iopub.status.idle":"2023-07-02T15:52:24.495378Z","shell.execute_reply":"2023-07-02T15:52:24.493873Z","shell.execute_reply.started":"2023-07-02T15:52:24.487875Z"},"trusted":true},"outputs":[],"source":["import pickle\n","# Save model\n","def save_model(file_name, model):\n","    with open('/kaggle/working/'+file_name,'wb') as f:\n","        pickle.dump(model,f)\n","    f.close()\n","\n","# Load model\n","def load_model(file_name):\n","    with open('/kaggle/working/'+file_name,'rb') as f:\n","        model = pickle.load(f)\n","    f.close()\n","    return model"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Load data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv('/kaggle/input/balance-data/balanced.csv')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Split train and test set"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X = df.iloc[:,:-1].to_numpy()\n","Y = df.iloc[:,-1].to_numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2, random_state=random.randint(1,999))\n","print(X_train.shape,X_test.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### RF and SVM"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Plot learning curve function"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def plot_learning_curve(model):\n","    train_sizes, train_scores, test_scores = learning_curve(estimator=model, X=X_train, y=Y_train,\n","                                                        cv=10, train_sizes=np.linspace(0.1, 1.0, 10),\n","                                                        n_jobs=1)\n","    #\n","    # Calculate training and test mean and std\n","    #\n","    train_mean = np.mean(train_scores, axis=1)\n","    train_std = np.std(train_scores, axis=1)\n","    test_mean = np.mean(test_scores, axis=1)\n","    test_std = np.std(test_scores, axis=1)\n","    #\n","    # Plot the learning curve\n","    #\n","    plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training Accuracy')\n","    plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n","    plt.plot(train_sizes, test_mean, color='green', marker='o', markersize=5, label='Validation Accuracy')\n","    plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n","    plt.title('Learning Curve')\n","    plt.xlabel('Training Data Size')\n","    plt.ylabel('Model accuracy')\n","    plt.grid()\n","    plt.legend(loc='lower right')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","\n","rfc = RandomForestClassifier(n_jobs=-1) \n","\n","parameters = {\n","    'n_estimators': [50, 100, 150, 200],\n","}\n","\n","clf = GridSearchCV(rfc, parameters)\n","clf.fit(X_train, Y_train)\n","print(sorted(clf.cv_results_.keys()))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["RF_clf = RandomForestClassifier()\n","plot_learning_curve(RF_clf)\n","RF_clf.fit(X_train, Y_train)\n","save_model('RF.pkl', RF_clf)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["RF_clf_Y_pred = RF_clf.predict(X_test)\n","print(classification_report(Y_test, RF_clf_Y_pred))\n","ConfusionMatrixDisplay.from_predictions(Y_test, RF_clf_Y_pred, normalize='true',values_format='.2f', xticks_rotation='vertical')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["SVM_clf = make_pipeline(StandardScaler(),PCA(n_components=20), SVC())\n","plot_learning_curve(SVM_clf)\n","SVM_clf.fit(X_train, Y_train)               \n","save_model('SVM.pkl', SVM_clf)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["SVM_clf_Y_pred = SVM_clf.predict(X_test)\n","print(classification_report(Y_test, SVM_clf_Y_pred))\n","ConfusionMatrixDisplay.from_predictions(Y_test, SVM_clf_Y_pred, normalize='true',values_format='.2f', xticks_rotation='vertical')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Cross eval"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["random_files = random.sample(range(21, 169), 5)\n","print(\"Used files: \", random_files)\n","\n","cross_df = pd.concat([pd.read_csv(data_path+f'part-{j:05d}-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv') for j in random_files])\n","\n","cross_df = convert_to_category(cross_df)\n","\n","cross_df.drop(high_corr_cols,axis=1, inplace=True)           \n","X_cross = cross_df.iloc[:,:-1].to_numpy()\n","Y_cross = cross_df.iloc[:,-1].to_numpy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(len(cross_df))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["RF_clf_cross_Y_pred = RF_clf.predict(X_cross)\n","print(classification_report(Y_cross, RF_clf_cross_Y_pred))\n","ConfusionMatrixDisplay.from_predictions(Y_cross, RF_clf_cross_Y_pred, normalize='true',values_format='.2f', xticks_rotation='vertical')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["SVM_clf_cross_Y_pred = SVM_clf.predict(X_cross)\n","print(classification_report(Y_cross, SVM_clf_cross_Y_pred))\n","ConfusionMatrixDisplay.from_predictions(Y_cross, SVM_clf_cross_Y_pred, normalize='true',values_format='.2f', xticks_rotation='vertical')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
